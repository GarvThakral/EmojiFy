{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ea79914-976a-4756-860a-13dea633cc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 13:32:11.573563: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755504131.607757  353907 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755504131.621778  353907 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755504131.675996  353907 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755504131.676062  353907 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755504131.676065  353907 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755504131.676067  353907 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-18 13:32:11.688037: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288561fd-12ee-4c54-95e4-3d9e3c4f5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datass/Files/glove.6B.50d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    word_to_vec_map = {}\n",
    "    word_to_index_map = {}\n",
    "    index_to_word_map = {}\n",
    "    index = 1\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        word_to_vec_map[word] = vector\n",
    "        word_to_index_map[word] = index\n",
    "        index_to_word_map[index] = word\n",
    "        index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d920154-c64f-4c6f-a4de-6bb4846862f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_indices(sentence,maxLength = 45):\n",
    "    m = sentence.shape[0]\n",
    "    finalArr = np.zeros((m,maxLength),dtype = 'int')\n",
    "    for i in range(m):\n",
    "        ind = 0\n",
    "        for j in sentence[i].lower().split():\n",
    "            if j in word_to_index_map.keys():\n",
    "                finalArr[i][ind] = word_to_index_map[j]\n",
    "                ind+=1\n",
    "    return finalArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11015668-578d-439c-ae45-46e93872fa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 13076,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0],\n",
       "       [   198,     33,     82,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0],\n",
       "       [243124,    193,   1607,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentArr = pd.array([\"hello\",\"how are you\",\"wassup my boy\"])\n",
    "sentence_to_indices(sentArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba11a823-dc3a-4d80-9ecb-e9445535900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map , index_to_word_map):\n",
    "    vocab_size = len(word_to_vec_map.keys()) + 1\n",
    "    random_word = word_to_vec_map['random']\n",
    "    \n",
    "    emb_matrix = np.zeros((vocab_size , random_word.shape[0]))\n",
    "    for idx,word in index_to_word_map.items():\n",
    "        emb_matrix[idx,:] = word_to_vec_map[word]\n",
    "    \n",
    "    embedding_layer = tf.keras.layers.Embedding(vocab_size , random_word.shape[0],trainable=False)\n",
    "    embedding_layer.build((None,)) # Do not modify the \"None\".  This line of code is complete as-is.\n",
    "    \n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3808534a-3547-42b1-a1fc-5ce76d6c48e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 13:32:34.566157: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-08-18 13:32:34.566207: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-08-18 13:32:34.566216: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: garvthakral-ROG-Zephyrus-G15-GA503RM\n",
      "2025-08-18 13:32:34.566221: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: garvthakral-ROG-Zephyrus-G15-GA503RM\n",
      "2025-08-18 13:32:34.566703: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 570.133.7\n",
      "2025-08-18 13:32:34.566762: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 570.133.7\n",
      "2025-08-18 13:32:34.566766: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 570.133.7\n",
      "2025-08-18 13:32:34.634922: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 80000200 exceeds 10% of free system memory.\n",
      "2025-08-18 13:32:34.684278: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 80000200 exceeds 10% of free system memory.\n",
      "2025-08-18 13:32:34.712847: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 80000200 exceeds 10% of free system memory.\n",
      "2025-08-18 13:32:35.728062: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 80000200 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map , index_to_word_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b186464e-e4c2-41f3-88a3-f321d3a8fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmojifyV2():\n",
    "    sentence_indices = tf.keras.layers.Input(shape=(45,), dtype='int32')\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "\n",
    "    # First LSTM returns sequences â†’ passes info for each timestep\n",
    "    X = tf.keras.layers.LSTM(units=128, return_sequences=True)(embeddings)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "    # Second LSTM just returns the final hidden state\n",
    "    X = tf.keras.layers.LSTM(units=128)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "    # Dense hidden layer for richer features\n",
    "    X = tf.keras.layers.Dense(64, activation='relu')(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "    # Output for 19 classes\n",
    "    X = tf.keras.layers.Dense(20, activation='softmax')(X)\n",
    "\n",
    "    model = tf.keras.Model(inputs=sentence_indices, outputs=X)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db19d388-67b7-41c2-8543-f8ada00f7d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,000,050</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">91,648</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,300</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m50\u001b[0m)         â”‚    \u001b[38;5;34m20,000,050\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m91,648\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚       \u001b[38;5;34m131,584\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             â”‚         \u001b[38;5;34m1,300\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,232,838</span> (77.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,232,838\u001b[0m (77.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">232,788</span> (909.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m232,788\u001b[0m (909.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,000,050</span> (76.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,000,050\u001b[0m (76.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model =  EmojifyV2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60f6f815-edca-4c01-9c4c-c3532721cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\"  ,optimizer='adam', metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fc27cb4-f542-4936-a37c-d040b944f5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 45000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"cardiffnlp/tweet_eval\", \"emoji\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b67fbf43-57de-41bb-99d2-ddaed30db8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_ds_train = ds['train'].to_tf_dataset()\n",
    "tf_ds_test = ds['test'].to_tf_dataset()\n",
    "tf_ds_valid = ds['validation'].to_tf_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9b02071-6e78-475a-b39c-fa85d4ac90ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Sunday afternoon walking through Venice in the sun with @user \\xef\\xb8\\x8f \\xef\\xb8\\x8f \\xef\\xb8\\x8f @ Abbot Kinney, Venice'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 13:32:42.642040: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for x in tf_ds_train.take(1):\n",
    "    print(x['text'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71c1b235-0348-4f0e-9a6d-6dcd14f9005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxLength = 0\n",
    "# for x in tf_ds_train:\n",
    "#     maxLength = max(maxLength,len(x['text'].numpy().split()))\n",
    "# print(maxLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218b4675-a136-4c57-bef9-37eb4d237d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxy = 0\n",
    "# for x in tf_ds_train:\n",
    "#     # print(tf.one_hot(x['label'],depth = 10))\n",
    "#     maxy = max(maxy,x['label'].numpy())\n",
    "# print(maxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91e42dad-0744-4961-9598-3a933c7b1f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  241  1503  3527   132  8082     7     1  1663    18    -1    -1    -1\n",
      "    -1 17528 16326    -1  8082     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0], shape=(45,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 13:32:43.624609: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "lookupTable = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(list(word_to_index_map.keys()),list(word_to_index_map.values())),\n",
    "    default_value = -1\n",
    ")\n",
    "def preprocess_data(example,max_len = 45,pad_value = 0):\n",
    "    example['text'] = tf.strings.lower(input = example['text'])\n",
    "    example['text'] = tf.strings.split(input = example['text'])\n",
    "    example['text'] = tf.ragged.map_flat_values(\n",
    "        lookupTable.lookup,\n",
    "        example['text']\n",
    "    )\n",
    "    example['text'] = example['text'][:max_len]\n",
    "    \n",
    "    # Pad if shorter than max_len\n",
    "    current_len = tf.shape(example['text'])[0]\n",
    "    pad_len = max_len - current_len\n",
    "    example['text'] = tf.pad(example['text'], [[0, pad_len]], constant_values=pad_value)\n",
    "    example['label']  = tf.one_hot(example['label'],depth = 20)\n",
    "    return (example['text'] , example['label'])\n",
    "for x,y in tf_ds_train.take(1).map(preprocess_data):\n",
    "    print(x)\n",
    "# tf_ds_train.take(1).map(preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63b76f90-c612-41d7-940e-de58f35c91ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_ds_train = tf_ds_train.map(preprocess_data).batch(34).prefetch(tf.data.AUTOTUNE) \n",
    "tf_ds_valid = tf_ds_valid.map(preprocess_data).batch(34).prefetch(tf.data.AUTOTUNE) \n",
    "tf_ds_test = tf_ds_test.map(preprocess_data).batch(34).prefetch(tf.data.AUTOTUNE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bda9d989-497f-4487-89f1-3456c4140fc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 68ms/step - accuracy: 0.1815 - loss: 2.7959\n",
      "Epoch 2/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 67ms/step - accuracy: 0.2062 - loss: 2.7036\n",
      "Epoch 3/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 62ms/step - accuracy: 0.2322 - loss: 2.6406\n",
      "Epoch 4/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 61ms/step - accuracy: 0.2450 - loss: 2.6055\n",
      "Epoch 5/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 64ms/step - accuracy: 0.2561 - loss: 2.5671\n",
      "Epoch 6/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 64ms/step - accuracy: 0.2664 - loss: 2.5270\n",
      "Epoch 7/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 67ms/step - accuracy: 0.2765 - loss: 2.4932\n",
      "Epoch 8/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 46ms/step - accuracy: 0.2824 - loss: 2.4649\n",
      "Epoch 9/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 41ms/step - accuracy: 0.2897 - loss: 2.4407\n",
      "Epoch 10/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 40ms/step - accuracy: 0.2969 - loss: 2.4149\n",
      "Epoch 11/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 39ms/step - accuracy: 0.3033 - loss: 2.3907\n",
      "Epoch 12/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 39ms/step - accuracy: 0.3118 - loss: 2.3668\n",
      "Epoch 13/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 42ms/step - accuracy: 0.3177 - loss: 2.3394\n",
      "Epoch 14/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 38ms/step - accuracy: 0.3263 - loss: 2.3146\n",
      "Epoch 15/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 39ms/step - accuracy: 0.3345 - loss: 2.2836\n",
      "Epoch 16/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 41ms/step - accuracy: 0.3431 - loss: 2.2511\n",
      "Epoch 17/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 41ms/step - accuracy: 0.3524 - loss: 2.2198\n",
      "Epoch 18/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 42ms/step - accuracy: 0.3564 - loss: 2.1972\n",
      "Epoch 19/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 44ms/step - accuracy: 0.3656 - loss: 2.1686\n",
      "Epoch 20/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 46ms/step - accuracy: 0.3730 - loss: 2.1359\n",
      "Epoch 21/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 44ms/step - accuracy: 0.3781 - loss: 2.1094\n",
      "Epoch 22/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 40ms/step - accuracy: 0.3824 - loss: 2.0875\n",
      "Epoch 23/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 39ms/step - accuracy: 0.3860 - loss: 2.0776\n",
      "Epoch 24/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 38ms/step - accuracy: 0.3938 - loss: 2.0420\n",
      "Epoch 25/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 38ms/step - accuracy: 0.3999 - loss: 2.0231\n",
      "Epoch 26/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 38ms/step - accuracy: 0.4032 - loss: 2.0004\n",
      "Epoch 27/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 38ms/step - accuracy: 0.4104 - loss: 1.9709\n",
      "Epoch 28/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 38ms/step - accuracy: 0.4124 - loss: 1.9606\n",
      "Epoch 29/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 38ms/step - accuracy: 0.4196 - loss: 1.9326\n",
      "Epoch 30/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 38ms/step - accuracy: 0.4165 - loss: 1.9259\n",
      "Epoch 31/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 38ms/step - accuracy: 0.4221 - loss: 1.9033\n",
      "Epoch 32/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 38ms/step - accuracy: 0.4272 - loss: 1.9003\n",
      "Epoch 33/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 38ms/step - accuracy: 0.4326 - loss: 1.8710\n",
      "Epoch 34/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 39ms/step - accuracy: 0.4317 - loss: 1.8682\n",
      "Epoch 35/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 39ms/step - accuracy: 0.4386 - loss: 1.8486\n",
      "Epoch 36/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 41ms/step - accuracy: 0.4381 - loss: 1.8281\n",
      "Epoch 37/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 42ms/step - accuracy: 0.4438 - loss: 1.8104\n",
      "Epoch 38/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 38ms/step - accuracy: 0.4461 - loss: 1.7998\n",
      "Epoch 39/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 40ms/step - accuracy: 0.4492 - loss: 1.7896\n",
      "Epoch 40/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 39ms/step - accuracy: 0.4526 - loss: 1.7810\n",
      "Epoch 41/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 43ms/step - accuracy: 0.4508 - loss: 1.7822\n",
      "Epoch 42/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 46ms/step - accuracy: 0.4536 - loss: 1.7732\n",
      "Epoch 43/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 47ms/step - accuracy: 0.4611 - loss: 1.7489\n",
      "Epoch 44/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 47ms/step - accuracy: 0.4625 - loss: 1.7297\n",
      "Epoch 45/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 45ms/step - accuracy: 0.4635 - loss: 1.7128\n",
      "Epoch 46/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 41ms/step - accuracy: 0.4688 - loss: 1.7051\n",
      "Epoch 47/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 41ms/step - accuracy: 0.4691 - loss: 1.7021\n",
      "Epoch 48/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 39ms/step - accuracy: 0.4726 - loss: 1.6902\n",
      "Epoch 49/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 40ms/step - accuracy: 0.4737 - loss: 1.6709\n",
      "Epoch 50/50\n",
      "\u001b[1m1324/1324\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 44ms/step - accuracy: 0.4788 - loss: 1.6591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7afe9de35e20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf_ds_train , epochs = 50, batch_size = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd19ea68-f739-42b6-8bcd-a1f19b889cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12b887f2-708f-408e-9c7b-b217879830f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 14:21:32.705568: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 80000200 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"my_model.keras\")\n",
    "model.compile(loss = \"categorical_crossentropy\" , optimizer = \"adam\" , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e92b518d-69b3-4cbe-89d7-746d94b97c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2276 - loss: 3.8696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.900615692138672, 0.22259999811649323]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(tf_ds_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9f8ba86-7a19-47c6-8813-aeb9921976f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_emoji = {\n",
    "    0: \"â¤\",\n",
    "    1: \"ğŸ˜\",\n",
    "    2: \"ğŸ˜‚\",\n",
    "    3: \"ğŸ’•\",\n",
    "    4: \"ğŸ”¥\",\n",
    "    5: \"ğŸ˜Š\",\n",
    "    6: \"ğŸ˜\",\n",
    "    7: \"âœ¨\",\n",
    "    8: \"ğŸ’™\",\n",
    "    9: \"ğŸ˜˜\",\n",
    "    10: \"ğŸ“·\",\n",
    "    11: \"ğŸ‡ºğŸ‡¸\",\n",
    "    12: \"â˜€\",\n",
    "    13: \"ğŸ’œ\",\n",
    "    14: \"ğŸ˜‰\",\n",
    "    15: \"ğŸ’¯\",\n",
    "    16: \"ğŸ˜\",\n",
    "    17: \"ğŸ„\",\n",
    "    18: \"ğŸ“¸\",\n",
    "    19: \"ğŸ˜œ\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2900d690-10ad-4b07-b013-7b5ed2ef4d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emoji(predArr,predictions):\n",
    "    for i in range(len(predictions)):\n",
    "        print(f\"{predArr[i]} {label_to_emoji[np.argmax(predictions[i])]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56479956-9b7d-4f8c-b131-8b110115801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "origArr = [\"I hate you\",\"Click a picture with me\"]\n",
    "predArr = sentence_to_indices(np.array(origArr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44a0d0bc-cb47-4a22-89cf-694dccc0a5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(predArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96b9adb4-1317-4ac9-bfd8-ffac34332b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hate you ğŸ˜‚\n",
      "Click a picture with me ğŸ˜‚\n"
     ]
    }
   ],
   "source": [
    "predict_emoji(origArr,predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
